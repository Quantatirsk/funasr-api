# -*- coding: utf-8 -*-
"""
æ¨¡å‹é¢„åŠ è½½å·¥å…·
åœ¨åº”ç”¨å¯åŠ¨æ—¶é¢„åŠ è½½æ‰€æœ‰éœ€è¦çš„æ¨¡å‹,é¿å…é¦–æ¬¡è¯·æ±‚æ—¶çš„å»¶è¿Ÿ
"""

import logging

logger = logging.getLogger(__name__)


def print_model_statistics(result: dict, use_logger: bool = True):
    """
    æ‰“å°æ¨¡å‹åŠ è½½ç»Ÿè®¡ä¿¡æ¯

    Args:
        result: preload_models() è¿”å›çš„ç»“æœå­—å…¸
        use_logger: Trueä½¿ç”¨loggerè¾“å‡ºï¼ˆè®°å½•åˆ°æ—¥å¿—ï¼‰ï¼ŒFalseä½¿ç”¨printè¾“å‡ºï¼ˆæ˜¾ç¤ºåˆ°æ§åˆ¶å°ï¼‰
    """
    output = logger.info if use_logger else print

    output("=" * 60)
    output("ğŸ“Š æ¨¡å‹åŠ è½½ç»Ÿè®¡ï¼š")
    output("-" * 60)

    loaded_models = []
    failed_models = []
    skipped_models = []
    model_index = 1  # åºå·è®¡æ•°å™¨

    # ç»Ÿè®¡æ‰€æœ‰ASRæ¨¡å‹
    for model_id, status in result["asr_models"].items():
        if status["loaded"]:
            loaded_models.append(f"ASRæ¨¡å‹({model_id})")
            output(f"   {model_index}. âœ… ASRæ¨¡å‹({model_id}): å·²åŠ è½½")
            model_index += 1
        elif status["error"] is not None:
            failed_models.append(f"ASRæ¨¡å‹({model_id})")
            if use_logger:
                logger.error(f"   {model_index}. âŒ ASRæ¨¡å‹({model_id}): {status['error']}")
            else:
                output(f"   {model_index}. âŒ ASRæ¨¡å‹({model_id}): {status['error']}")
            model_index += 1

    # ç»Ÿè®¡å…¶ä»–æ¨¡å‹ï¼ˆæŒ‰ä¼˜åŒ–åçš„é¡ºåºï¼‰
    other_models = [
        ("vad_model", "è¯­éŸ³æ´»åŠ¨æ£€æµ‹æ¨¡å‹(VAD)"),
        ("punc_model", "æ ‡ç‚¹ç¬¦å·æ¨¡å‹(ç¦»çº¿)"),
        ("punc_realtime_model", "æ ‡ç‚¹ç¬¦å·æ¨¡å‹(å®æ—¶)"),
        ("speaker_diarization_model", "è¯´è¯äººåˆ†ç¦»æ¨¡å‹(CAM++)"),
    ]

    for key, name in other_models:
        if result[key]["loaded"]:
            loaded_models.append(name)
            output(f"   {model_index}. âœ… {name}: å·²åŠ è½½")
            model_index += 1
        elif result[key]["error"] is not None:
            failed_models.append(name)
            if use_logger:
                logger.error(f"   {model_index}. âŒ {name}: {result[key]['error']}")
            else:
                output(f"   {model_index}. âŒ {name}: {result[key]['error']}")
            model_index += 1
        else:
            skipped_models.append(name)
            output(f"   {model_index}. â­ï¸  {name}: å·²è·³è¿‡")
            model_index += 1

    output("-" * 60)
    loaded_count = len(loaded_models)
    total_count = loaded_count + len(failed_models)

    if loaded_count == total_count and total_count > 0:
        output(
            f"ğŸ‰ æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæˆ! (æˆåŠŸ: {loaded_count}, è·³è¿‡: {len(skipped_models)})"
        )
    elif total_count > 0:
        if use_logger:
            logger.warning(
                f"âš ï¸  éƒ¨åˆ†æ¨¡å‹åŠ è½½å¤±è´¥ (æˆåŠŸ: {loaded_count}/{total_count}, å¤±è´¥: {len(failed_models)}, è·³è¿‡: {len(skipped_models)})"
            )
        else:
            output(
                f"âš ï¸  éƒ¨åˆ†æ¨¡å‹åŠ è½½å¤±è´¥ (æˆåŠŸ: {loaded_count}/{total_count}, å¤±è´¥: {len(failed_models)}, è·³è¿‡: {len(skipped_models)})"
            )
    else:
        if use_logger:
            logger.warning("âš ï¸  æ²¡æœ‰æ¨¡å‹è¢«åŠ è½½")
        else:
            output("âš ï¸  æ²¡æœ‰æ¨¡å‹è¢«åŠ è½½")

    output("=" * 60)


def _has_cuda() -> bool:
    """æ£€æŸ¥æ˜¯å¦æœ‰ CUDA å¯ç”¨"""
    try:
        import torch
        return torch.cuda.is_available()
    except Exception:
        return False


def _detect_qwen_model_by_vram() -> str | None:
    """æ ¹æ®æ˜¾å­˜æ£€æµ‹åº”è¯¥ä½¿ç”¨å“ªä¸ª Qwen æ¨¡å‹

    < 32GB ç”¨ 0.6b, >= 32GB ç”¨ 1.7b
    CPU ç¯å¢ƒè¿”å› Noneï¼ˆvLLM ä¸æ”¯æŒ CPUï¼‰
    """
    if not _has_cuda():
        return None

    try:
        import torch

        min_vram = min(
            torch.cuda.get_device_properties(i).total_memory / (1024**3)
            for i in range(torch.cuda.device_count())
        )
        return "qwen3-asr-1.7b" if min_vram >= 32 else "qwen3-asr-0.6b"
    except Exception:
        return "qwen3-asr-0.6b"


def _resolve_models_to_load(all_available_models: list[str], config: str) -> list[str]:
    """è§£æé…ç½®ï¼Œè¿”å›åº”åŠ è½½çš„æ¨¡å‹åˆ—è¡¨

    CPU ç¯å¢ƒä¸‹è‡ªåŠ¨è¿‡æ»¤ Qwen æ¨¡å‹ï¼ˆvLLM ä¸æ”¯æŒ CPUï¼‰

    Args:
        all_available_models: æ‰€æœ‰å¯ç”¨æ¨¡å‹ID
        config: ENABLED_MODELS é…ç½®å€¼

    Returns:
        åº”åŠ è½½çš„æ¨¡å‹IDåˆ—è¡¨
    """
    cfg = config.strip().lower()
    has_cuda = _has_cuda()

    # all: åŠ è½½æ‰€æœ‰ï¼ˆCPU ä¸‹è¿‡æ»¤ Qwenï¼‰
    if cfg == "all":
        if has_cuda:
            return all_available_models
        # CPU: åªåŠ è½½é Qwen æ¨¡å‹
        return [m for m in all_available_models if not m.startswith("qwen3-asr-")]

    # auto: è‡ªåŠ¨æ£€æµ‹æ˜¾å­˜ + paraformer-large
    if cfg == "auto":
        qwen_model = _detect_qwen_model_by_vram()
        models = []
        if qwen_model and qwen_model in all_available_models:
            models.append(qwen_model)
        if "paraformer-large" in all_available_models:
            models.append("paraformer-large")
        return models

    # å…¶ä»–: ç²¾ç¡®åŒ¹é…ï¼Œè¿‡æ»¤æ‰ä¸å­˜åœ¨çš„ï¼ˆCPU ä¸‹é¢å¤–è¿‡æ»¤ Qwenï¼‰
    requested = [m.strip() for m in config.split(",") if m.strip()]
    result = [m for m in requested if m in all_available_models]
    if not has_cuda:
        # CPU ç¯å¢ƒè¿‡æ»¤ Qwen
        result = [m for m in result if not m.startswith("qwen3-asr-")]
    return result


def preload_models() -> dict:
    """
    é¢„åŠ è½½æ‰€æœ‰éœ€è¦çš„æ¨¡å‹ï¼ˆæ ¹æ® ENABLE_* é…ç½®è¿‡æ»¤ï¼‰

    Returns:
        dict: åŒ…å«åŠ è½½çŠ¶æ€çš„å­—å…¸
    """
    # ä¿®å¤ CAM++ é…ç½®æ–‡ä»¶ï¼ˆç”¨äºç¦»çº¿ç¯å¢ƒï¼‰
    try:
        from .download_models import fix_camplusplus_config
        fix_camplusplus_config()
    except Exception:
        pass  # ä¿®å¤å¤±è´¥ä¸å½±å“å¯åŠ¨

    result = {
        "asr_models": {},  # æ‰€æœ‰ASRæ¨¡å‹åŠ è½½çŠ¶æ€
        "vad_model": {"loaded": False, "error": None},
        "punc_model": {"loaded": False, "error": None},
        "punc_realtime_model": {"loaded": False, "error": None},
        "speaker_diarization_model": {"loaded": False, "error": None},
    }

    from ..core.config import settings
    from ..services.asr.registry import register_loaded_model

    # åˆå§‹åŒ–å˜é‡ï¼Œé¿å…æœªç»‘å®šé”™è¯¯
    asr_engine = None
    model_manager = None

    logger.info("=" * 60)
    logger.info("ğŸ”„ å¼€å§‹é¢„åŠ è½½æ¨¡å‹...")
    logger.info(f"   é…ç½®: ENABLED_MODELS={settings.ENABLED_MODELS}")
    logger.info("=" * 60)

    # 1. é¢„åŠ è½½æ‰€æœ‰é…ç½®çš„ASRæ¨¡å‹ï¼ˆæ ¹æ® ENABLE_* é…ç½®è¿‡æ»¤ï¼‰
    try:
        from ..services.asr.manager import get_model_manager

        model_manager = get_model_manager()

        # è·å–æ‰€æœ‰æ¨¡å‹é…ç½®
        all_models = model_manager.list_models()
        model_ids = [m["id"] for m in all_models]

        # æ ¹æ®é…ç½®è§£æåº”åŠ è½½çš„æ¨¡å‹
        models_to_load = _resolve_models_to_load(model_ids, settings.ENABLED_MODELS)

        # å¦‚æœæ²¡æœ‰å¯ç”¨ä»»ä½•æ¨¡å‹ï¼Œå‘å‡ºè­¦å‘Š
        if not models_to_load:
            logger.warning(f"âš ï¸  æ²¡æœ‰å¯ç”¨ä»»ä½• ASR æ¨¡å‹ï¼è¯·æ£€æŸ¥ ENABLED_MODELS é…ç½®: {settings.ENABLED_MODELS}")

        logger.info(f"ğŸ“‹ å‘ç° {len(model_ids)} ä¸ªæ¨¡å‹é…ç½®ï¼Œå°†åŠ è½½ {len(models_to_load)} ä¸ª: {', '.join(models_to_load) if models_to_load else 'ï¼ˆæ— ï¼‰'}")

        for model_id in models_to_load:
            result["asr_models"][model_id] = {"loaded": False, "error": None}

            try:
                engine = model_manager.get_asr_engine(model_id)

                if engine.is_model_loaded():
                    result["asr_models"][model_id]["loaded"] = True
                    register_loaded_model(model_id)  # æ³¨å†Œåˆ°å…¨å±€æ³¨å†Œè¡¨

                    # ä¿å­˜ç¬¬ä¸€ä¸ªæˆåŠŸåŠ è½½çš„å¼•æ“å¼•ç”¨ï¼ˆç”¨äºåç»­è·å–deviceï¼‰
                    if asr_engine is None:
                        asr_engine = engine
                else:
                    result["asr_models"][model_id]["error"] = "æ¨¡å‹åŠ è½½åæœªæ­£ç¡®åˆå§‹åŒ–"

                # ä¸º Qwen3-ASR åŠ è½½æµå¼ä¸“ç”¨å®ä¾‹ï¼ˆå®Œå…¨éš”ç¦»çŠ¶æ€ï¼‰
                # ä»…åœ¨ ENABLE_STREAMING_VLLM=true æ—¶åŠ è½½æµå¼å®ä¾‹ï¼ˆé»˜è®¤ falseï¼ŒèŠ‚çœæ˜¾å­˜ï¼‰
                if settings.ENABLE_STREAMING_VLLM and model_id.startswith("qwen3-asr-"):
                    streaming_key = f"{model_id}-streaming"
                    result["asr_models"][streaming_key] = {"loaded": False, "error": None}
                    try:
                        streaming_engine = model_manager.get_asr_engine(model_id, streaming=True)
                        if streaming_engine.is_model_loaded():
                            result["asr_models"][streaming_key]["loaded"] = True
                        else:
                            result["asr_models"][streaming_key]["error"] = "æ¨¡å‹åŠ è½½åæœªæ­£ç¡®åˆå§‹åŒ–"
                    except Exception as e:
                        result["asr_models"][streaming_key]["error"] = str(e)

            except Exception as e:
                result["asr_models"][model_id]["error"] = str(e)

    except Exception as e:
        logger.error(f"âŒ è·å–æ¨¡å‹ç®¡ç†å™¨å¤±è´¥: {e}")
        models_to_load = []

    # è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥æ˜¯å¦è¦åŠ è½½ paraformer
    paraformer_enabled = "paraformer-large" in models_to_load

    # 2. é¢„åŠ è½½è¯­éŸ³æ´»åŠ¨æ£€æµ‹æ¨¡å‹(VAD)
    # VAD æ˜¯ Paraformer çš„é…å¥—æ¨¡å‹ï¼Œåªæœ‰å¯ç”¨ Paraformer æ—¶æ‰åŠ è½½
    if paraformer_enabled:
        try:
            from ..services.asr.engines import get_global_vad_model

            device = asr_engine.device if asr_engine else settings.DEVICE
            vad_model = get_global_vad_model(device)

            if vad_model:
                result["vad_model"]["loaded"] = True
            else:
                result["vad_model"]["error"] = "è¯­éŸ³æ´»åŠ¨æ£€æµ‹æ¨¡å‹(VAD)åŠ è½½åè¿”å›None"

        except Exception as e:
            result["vad_model"]["error"] = str(e)
            logger.error(f"âŒ è¯­éŸ³æ´»åŠ¨æ£€æµ‹æ¨¡å‹(VAD)åŠ è½½å¤±è´¥: {e}")
    else:
        result["vad_model"]["error"] = "å·²è·³è¿‡ï¼ˆParaformer æœªå¯ç”¨ï¼‰"
        logger.info("â­ï¸  è·³è¿‡ VAD æ¨¡å‹åŠ è½½ï¼ˆParaformer æœªå¯ç”¨ï¼‰")

    # 3. é¢„åŠ è½½æ ‡ç‚¹ç¬¦å·æ¨¡å‹ (ç¦»çº¿ç‰ˆ)
    # PUNC æ˜¯ Paraformer çš„é…å¥—æ¨¡å‹ï¼Œåªæœ‰å¯ç”¨ Paraformer æ—¶æ‰åŠ è½½
    if paraformer_enabled:
        try:
            from ..services.asr.engines import get_global_punc_model

            device = asr_engine.device if asr_engine else settings.DEVICE
            punc_model = get_global_punc_model(device)

            if punc_model:
                result["punc_model"]["loaded"] = True
            else:
                result["punc_model"]["error"] = "æ ‡ç‚¹ç¬¦å·æ¨¡å‹åŠ è½½åè¿”å›None"

        except Exception as e:
            result["punc_model"]["error"] = str(e)
            logger.error(f"âŒ æ ‡ç‚¹ç¬¦å·æ¨¡å‹(ç¦»çº¿)åŠ è½½å¤±è´¥: {e}")
    else:
        result["punc_model"]["error"] = "å·²è·³è¿‡ï¼ˆParaformer æœªå¯ç”¨ï¼‰"
        logger.info("â­ï¸  è·³è¿‡æ ‡ç‚¹æ¨¡å‹åŠ è½½ï¼ˆParaformer æœªå¯ç”¨ï¼‰")

    # 4. é¢„åŠ è½½å®æ—¶æ ‡ç‚¹ç¬¦å·æ¨¡å‹ (å¦‚æœå¯ç”¨)
    if paraformer_enabled and settings.ASR_ENABLE_REALTIME_PUNC:
        try:
            from ..services.asr.engines import get_global_punc_realtime_model

            device = asr_engine.device if asr_engine else settings.DEVICE
            punc_realtime_model = get_global_punc_realtime_model(device)

            if punc_realtime_model:
                result["punc_realtime_model"]["loaded"] = True
            else:
                result["punc_realtime_model"]["error"] = "å®æ—¶æ ‡ç‚¹ç¬¦å·æ¨¡å‹åŠ è½½åè¿”å›None"

        except Exception as e:
            result["punc_realtime_model"]["error"] = str(e)
            logger.error(f"âŒ å®æ—¶æ ‡ç‚¹ç¬¦å·æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    else:
        skip_reason = "Paraformer æœªå¯ç”¨" if not paraformer_enabled else "å®æ—¶æ ‡ç‚¹è¢«ç¦ç”¨"
        result["punc_realtime_model"]["error"] = f"å·²è·³è¿‡ï¼ˆ{skip_reason}ï¼‰"
        logger.info(f"â­ï¸  è·³è¿‡å®æ—¶æ ‡ç‚¹æ¨¡å‹åŠ è½½ï¼ˆ{skip_reason}ï¼‰")

    # 5. é¢„åŠ è½½è¯´è¯äººåˆ†ç¦»æ¨¡å‹ (CAM++) - å¿…éœ€æ¨¡å‹ï¼Œå§‹ç»ˆåŠ è½½
    try:
        from ..utils.speaker_diarizer import get_global_diarization_pipeline

        diarization_pipeline = get_global_diarization_pipeline()

        if diarization_pipeline:
            result["speaker_diarization_model"]["loaded"] = True
        else:
            result["speaker_diarization_model"]["error"] = "è¯´è¯äººåˆ†ç¦»æ¨¡å‹åŠ è½½åè¿”å›None"

    except Exception as e:
        result["speaker_diarization_model"]["error"] = str(e)
        logger.error(f"âŒ è¯´è¯äººåˆ†ç¦»æ¨¡å‹(CAM++)åŠ è½½å¤±è´¥: {e}")

    return result
