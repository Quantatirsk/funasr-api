#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹é¢„ä¸‹è½½è„šæœ¬
ç”¨äºæ„å»º Docker é•œåƒæ—¶é¢„ä¸‹è½½æ‰€æœ‰æ¨¡å‹
"""

import os

# å¼ºåˆ¶ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹ç¼“å­˜è·¯å¾„ï¼Œé¿å… MODELSCOPE_CACHE ç¯å¢ƒå˜é‡å¹²æ‰°
# æ ‡å‡†è·¯å¾„: ~/.cache/modelscope/hub/models/{model_id}/
MODELSCOPE_BASE_PATH = os.path.expanduser("~/.cache/modelscope")

# è®¾ç½® HuggingFace ç¼“å­˜ç›®å½•ï¼ˆå¦‚æœæœªè®¾ç½®ï¼‰
if "HF_HOME" not in os.environ:
    os.environ["HF_HOME"] = os.path.expanduser("~/.cache/huggingface")


# æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶å·²ç§»é™¤ï¼Œå…¨éƒ¨ä½¿ç”¨ ModelScope é»˜è®¤ç‰ˆæœ¬
MODEL_REVISIONS = {}

# === ModelScope æ¨¡å‹åˆ—è¡¨ ===
MODELSCOPE_MODELS = [
    ("iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch", "Paraformer Large ç¦»çº¿æ¨¡å‹(VAD+æ ‡ç‚¹)"),
    ("iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online", "Paraformer Large å®æ—¶æ¨¡å‹"),
    ("iic/speech_fsmn_vad_zh-cn-16k-common-pytorch", "è¯­éŸ³æ´»åŠ¨æ£€æµ‹æ¨¡å‹(VAD) - iic"),
    ("damo/speech_fsmn_vad_zh-cn-16k-common-pytorch", "è¯­éŸ³æ´»åŠ¨æ£€æµ‹æ¨¡å‹(VAD) - damo"),
    ("iic/speech_campplus_speaker-diarization_common", "è¯´è¯äººåˆ†ç¦»æ¨¡å‹(CAM++)"),
    ("damo/speech_campplus_sv_zh-cn_16k-common", "å£°çº¹è¯†åˆ«æ¨¡å‹(CAM++ä¾èµ–)"),
    ("damo/speech_campplus-transformer_scl_zh-cn_16k-common", "CAM++ transformeræ¨¡å‹(è¯´è¯äººåˆ†ç¦»ä¾èµ–)"),
    ("iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch", "æ ‡ç‚¹ç¬¦å·æ¨¡å‹(ç¦»çº¿)"),
    ("iic/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727", "æ ‡ç‚¹ç¬¦å·æ¨¡å‹(å®æ—¶)"),
    ("iic/speech_ngram_lm_zh-cn-ai-wesp-fst", "è¯­è¨€æ¨¡å‹(N-gram LM)"),
]

# === HuggingFace æ¨¡å‹åˆ—è¡¨ ===
HUGGINGFACE_MODELS = [
    ("Qwen/Qwen3-ASR-1.7B", "Qwen3-ASR 1.7B (vLLM åç«¯)"),
]


def check_model_exists(model_id: str, cache_dir: str) -> tuple[bool, str]:
    """æ£€æŸ¥ ModelScope æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨äºæœ¬åœ°ç¼“å­˜

    æ ‡å‡†è·¯å¾„: ~/.cache/modelscope/hub/models/{model_id}/
    """
    from pathlib import Path

    model_path = Path(cache_dir) / "hub" / "models" / model_id

    if model_path.exists() and model_path.is_dir():
        if any(model_path.iterdir()):
            return True, str(model_path)

    return False, ""


def check_hf_model_exists(model_id: str, cache_dir: str) -> tuple[bool, str]:
    """æ£€æŸ¥ HuggingFace æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨äºæœ¬åœ°ç¼“å­˜"""
    from pathlib import Path

    org, name = model_id.split("/")
    model_path = Path(cache_dir) / "hub" / f"models--{org}--{name}"

    if model_path.exists() and model_path.is_dir():
        snapshots_dir = model_path / "snapshots"
        if snapshots_dir.exists() and any(snapshots_dir.iterdir()):
            return True, str(model_path)

    return False, ""


def check_all_models() -> tuple[list[str], list[str]]:
    """æ£€æŸ¥æ‰€æœ‰æ¨¡å‹æ˜¯å¦å­˜åœ¨

    Returns:
        (missing_ms_models, missing_hf_models) - ç¼ºå¤±çš„æ¨¡å‹IDåˆ—è¡¨
    """
    cache_dir = MODELSCOPE_BASE_PATH
    hf_cache_dir = os.environ.get('HF_HOME', os.path.expanduser('~/.cache/huggingface'))

    missing_ms = []
    for model_id, _ in MODELSCOPE_MODELS:
        exists, _ = check_model_exists(model_id, cache_dir)
        if not exists:
            missing_ms.append(model_id)

    missing_hf = []
    for model_id, _ in HUGGINGFACE_MODELS:
        exists, _ = check_hf_model_exists(model_id, hf_cache_dir)
        if not exists:
            missing_hf.append(model_id)

    return missing_ms, missing_hf


def download_models(auto_mode: bool = False) -> bool:
    """ä¸‹è½½æ‰€æœ‰éœ€è¦çš„æ¨¡å‹

    Args:
        auto_mode: å¦‚æœä¸ºTrueï¼Œè¡¨ç¤ºè‡ªåŠ¨æ¨¡å¼ï¼ˆä»start.pyè°ƒç”¨ï¼‰ï¼Œä¼šç®€åŒ–è¾“å‡º

    Returns:
        æ˜¯å¦å…¨éƒ¨ä¸‹è½½æˆåŠŸ
    """
    from modelscope.hub.snapshot_download import snapshot_download

    cache_dir = MODELSCOPE_BASE_PATH
    hf_cache_dir = os.environ.get('HF_HOME', os.path.expanduser('~/.cache/huggingface'))

    # æ£€æŸ¥ç¼ºå¤±çš„æ¨¡å‹
    missing_ms, missing_hf = check_all_models()

    if not missing_ms and not missing_hf:
        if not auto_mode:
            print("âœ… æ‰€æœ‰æ¨¡å‹å·²å­˜åœ¨ï¼Œæ— éœ€ä¸‹è½½")
        return True

    if auto_mode:
        print(f"ğŸ“¦ æ£€æµ‹åˆ° {len(missing_ms)} ä¸ª ModelScope æ¨¡å‹ã€{len(missing_hf)} ä¸ª HuggingFace æ¨¡å‹éœ€è¦ä¸‹è½½...")
    else:
        print("=" * 60)
        print("FunASR-API æ¨¡å‹é¢„ä¸‹è½½")
        print("=" * 60)
        print(f"ModelScope ç¼“å­˜: {cache_dir}")
        print(f"HuggingFace ç¼“å­˜: {hf_cache_dir}")
        print(f"å¾…ä¸‹è½½ ModelScope æ¨¡å‹: {len(missing_ms)} ä¸ª")
        print(f"å¾…ä¸‹è½½ HuggingFace æ¨¡å‹: {len(missing_hf)} ä¸ª")
        print("=" * 60)

    failed = []
    skipped = []
    downloaded = []

    # ä¸‹è½½ ModelScope æ¨¡å‹
    if missing_ms:
        if not auto_mode:
            print("\nğŸ“¦ å¼€å§‹ä¸‹è½½ ModelScope æ¨¡å‹...")
            print("-" * 60)

        for i, (model_id, desc) in enumerate(MODELSCOPE_MODELS, 1):
            if model_id not in missing_ms:
                continue

            if not auto_mode:
                print(f"\n[{i}/{len(MODELSCOPE_MODELS)}] {desc}")
                print(f"    æ¨¡å‹ID: {model_id}")
                print(f"    ğŸ“¥ å¼€å§‹ä¸‹è½½...", end="")

            try:
                # æ˜¾å¼æŒ‡å®šç¼“å­˜ç›®å½•ï¼Œç¡®ä¿ä¸‹è½½åˆ°æ ‡å‡†è·¯å¾„
                path = snapshot_download(model_id, cache_dir=MODELSCOPE_BASE_PATH)
                if not auto_mode:
                    print(f" âœ… å®Œæˆ: {path}")
                downloaded.append(f"MS:{model_id}")
            except Exception as e:
                if not auto_mode:
                    print(f" âŒ å¤±è´¥: {e}")
                failed.append((f"MS:{model_id}", str(e)))

    # ä¸‹è½½ HuggingFace æ¨¡å‹
    if missing_hf:
        if not auto_mode:
            print("\nğŸ“¦ å¼€å§‹ä¸‹è½½ HuggingFace æ¨¡å‹...")
            print("-" * 60)

        try:
            from huggingface_hub import snapshot_download as hf_snapshot_download
        except ImportError:
            print("âš ï¸  huggingface_hub æœªå®‰è£…ï¼Œè·³è¿‡ HuggingFace æ¨¡å‹ä¸‹è½½")
            print("    å¦‚éœ€ä¸‹è½½ï¼Œè¯·è¿è¡Œ: pip install huggingface_hub")
            hf_snapshot_download = None

        if hf_snapshot_download:
            for model_id, desc in HUGGINGFACE_MODELS:
                if model_id not in missing_hf:
                    continue

                if not auto_mode:
                    print(f"\n{desc}")
                    print(f"    æ¨¡å‹ID: {model_id}")
                    print(f"    ğŸ“¥ å¼€å§‹ä¸‹è½½...", end="")

                try:
                    path = hf_snapshot_download(model_id)
                    if not auto_mode:
                        print(f" âœ… å®Œæˆ: {path}")
                    downloaded.append(f"HF:{model_id}")
                except Exception as e:
                    if not auto_mode:
                        print(f" âŒ å¤±è´¥: {e}")
                    failed.append((f"HF:{model_id}", str(e)))

    if not auto_mode:
        print("\n" + "=" * 60)
        print("ğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
        print(f"  âœ… å·²ä¸‹è½½: {len(downloaded)} ä¸ª")
        print(f"  â­ï¸  å·²è·³è¿‡: {len(skipped)} ä¸ª")
        print(f"  âŒ å¤±è´¥: {len(failed)} ä¸ª")
        print("=" * 60)

        if failed:
            print(f"\nå¤±è´¥çš„æ¨¡å‹:")
            for model_id, err in failed:
                print(f"  - {model_id}: {err}")
            return False
        else:
            print("\nâœ… æ‰€æœ‰æ¨¡å‹å‡†å¤‡å°±ç»ª!")
            print("=" * 60)

    return len(failed) == 0


if __name__ == "__main__":
    download_models()
