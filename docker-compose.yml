services:
  nginx:
    image: nginx:1.27-alpine
    container_name: funasr-nginx
    ports:
      - "17003:80"
    volumes:
      - ./funasr.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - funasr-api
    restart: unless-stopped
    networks:
      - funasr-net

  # 单节点：用线程池实现并发与排队（适合离线长音频）
  funasr-api:
    image: quantatrisk/funasr-api:gpu-latest
    container_name: funasr-api
    expose:
      - "8000"
    volumes:
      - ./temp:/app/temp
      - ./data:/app/data
      - ./logs:/app/logs
      - ./models:/root/.cache/modelscope
    environment:
      - DEBUG=false
      - LOG_LEVEL=INFO
      - HOST=0.0.0.0
      - PORT=8000
      - DEVICE=cuda:0
      # Qwen3-ASR 模型选择: auto (自动检测显存), Qwen3-ASR-1.7B, Qwen3-ASR-0.6B
      # - QWEN_ASR_MODEL=auto
      - NVIDIA_VISIBLE_DEVICES=0
      # 多进程会复制模型、显存成倍增加；离线长音频建议保持 1
      - WORKERS=1
      # 推理线程池大小决定"同时跑推理的数量"，其余请求会在队列中等待
      # 建议从 2~4 开始逐步调参
      - INFERENCE_THREAD_POOL_SIZE=4
      # ASR 批处理大小（同时推理的音频片段数）
      # 批处理利用 GPU 并行计算，可提升 2-3 倍速度，建议 2-8
      - ASR_BATCH_SIZE=4
      # 最大音频文件大小限制（单位：MB，默认 2048 = 2GB）
      # 支持格式：纯数字表示 MB，或带单位如 2GB
      - MAX_AUDIO_SIZE=2048
    restart: unless-stopped
    networks:
      - funasr-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]

networks:
  funasr-net:
    name: funasr-net
