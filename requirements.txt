# FastAPI: 与 vLLM 兼容，允许 0.115.0-0.128.x
fastapi>=0.115.0,<0.130.0
fastapi-offline==1.7.6
uvicorn[standard]==0.34.0

# Pydantic: 明确使用 v2（vLLM 要求 >=2.12.0）
pydantic>=2.12.0,<3.0.0
python-multipart==0.0.22
funasr==1.3.1
requests==2.32.5
modelscope[framework]==1.34.0
soundfile==0.13.1
librosa==0.11.0
pydub==0.25.1
websockets==16.0
addict==2.4.0
datasets==3.6.0
scipy==1.15.3
httpx==0.28.1
wetext==0.1.2
python-dotenv==1.2.1
# transformers: qwen-asr 固定了 4.57.6，跟随其依赖
# huggingface_hub: transformers 4.57.6 要求 <1.0
transformers==4.57.6
huggingface_hub>=0.34.0,<1.0
hdbscan>=0.8.41
loguru>=0.7.2

# Qwen3-ASR
# 使用 vLLM 后端需要安装 qwen-asr[vllm]
# 注意：需要先安装 vLLM，建议使用官方镜像或 pip install vllm
qwen-asr[vllm]>=0.0.6